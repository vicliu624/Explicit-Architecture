#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
data_builder.py
----------------------------------------------------
æ˜¾æ€§æ¶æ„å®éªŒæ•°æ®æ„å»ºè„šæœ¬

åŠŸèƒ½ï¼š
1. éå†æºä»£ç é¡¹ç›®ï¼Œç”Ÿæˆæ˜¾æ€§/éæ˜¾æ€§æ¶æ„å‰¯æœ¬
2. æ„é€ å‡½æ•°è¡¥å…¨ä»»åŠ¡æ ·æœ¬
3. è®¡ç®—å‡½æ•°é—´è€¦åˆåº¦æŒ‡æ ‡
4. è¾“å‡ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†

ä¾èµ–ï¼š
    pip install astor tqdm networkx scikit-learn matplotlib pandas scipy
----------------------------------------------------
"""

import os
import ast
import json
import random
import shutil
import networkx as nx
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
from pathlib import Path
from sklearn.model_selection import train_test_split
from scipy.stats import ttest_ind


# ========= åŸºç¡€å·¥å…· ==========
def ensure_dir(path):
    """ç¡®ä¿ç›®å½•å­˜åœ¨"""
    os.makedirs(path, exist_ok=True)


def list_source_files(base_dir, supported_extensions=None):
    """é€’å½’åˆ—å‡ºç›®å½•ä¸‹çš„æ‰€æœ‰æºä»£ç æ–‡ä»¶"""
    if supported_extensions is None:
        supported_extensions = [".py", ".java", ".js", ".ts", ".cpp", ".c", ".cs", ".go", ".rs"]
    
    source_files = []
    for root, _, files in os.walk(base_dir):
        for f in files:
            if any(f.endswith(ext) for ext in supported_extensions):
                source_files.append(os.path.join(root, f))
    return source_files


# ========= 1ï¸âƒ£ æ˜¾æ€§ / éæ˜¾æ€§ å‰¯æœ¬ç”Ÿæˆ ==========
def make_copies(src_dir, out_dir):
    """
    ç”Ÿæˆæ˜¾æ€§å’Œéæ˜¾æ€§æ¶æ„å‰¯æœ¬
    
    Args:
        src_dir: æºä»£ç ç›®å½•
        out_dir: è¾“å‡ºç›®å½•
        
    Returns:
        tuple: (explicit_dir, implicit_dir) è·¯å¾„
    """
    explicit_dir = Path(out_dir) / "explicit_view"
    implicit_dir = Path(out_dir) / "non_explicit_view"
    ensure_dir(explicit_dir)
    ensure_dir(implicit_dir)

    print(f"ğŸ“ å¤„ç†æºä»£ç ç›®å½•: {src_dir}")
    source_files = list_source_files(src_dir)
    print(f"ğŸ“„ å‘ç° {len(source_files)} ä¸ªæºä»£ç æ–‡ä»¶")

    for f in tqdm(source_files, desc="ç”Ÿæˆæ¶æ„å‰¯æœ¬"):
        rel_path = os.path.relpath(f, src_dir)
        
        # æ˜¾æ€§æ¶æ„å‰¯æœ¬ï¼šä¿æŒåŸæœ‰ç›®å½•ç»“æ„
        explicit_dst = explicit_dir / rel_path
        ensure_dir(explicit_dst.parent)
        shutil.copy(f, explicit_dst)
        
        # æ·»åŠ è·¯å¾„æ³¨é‡Šä»¥å¢å¼ºä½ç½®ä¿¡å·
        try:
            with open(explicit_dst, "r", encoding="utf-8") as src_file:
                content = src_file.read()
            path_comment = f"# FILE_PATH: {rel_path}\n"
            with open(explicit_dst, "w", encoding="utf-8") as dst_file:
                dst_file.write(path_comment + content)
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ä»¶å¤±è´¥: {explicit_dst} - {e}")
        
        # éæ˜¾æ€§æ¶æ„å‰¯æœ¬ï¼šæ‰“ä¹±ç»“æ„ï¼Œéšæœºå‘½å
        file_hash = abs(hash(rel_path)) % 999999
        file_ext = os.path.splitext(f)[1]  # ä¿æŒåŸæ–‡ä»¶æ‰©å±•å
        implicit_dst = implicit_dir / f"file_{file_hash:06d}{file_ext}"
        shutil.copy(f, implicit_dst)

    print(f"âœ… å·²ç”Ÿæˆæ˜¾æ€§/éæ˜¾æ€§å‰¯æœ¬")
    print(f"   æ˜¾æ€§æ¶æ„: {explicit_dir}")
    print(f"   éæ˜¾æ€§æ¶æ„: {implicit_dir}")
    
    return str(explicit_dir), str(implicit_dir)


# ========= 2ï¸âƒ£ å‡½æ•°è¡¥å…¨ä»»åŠ¡æ ·æœ¬ç”Ÿæˆ ==========
def make_completion_samples(project_dir, label):
    """
    ç”Ÿæˆå‡½æ•°è¡¥å…¨ä»»åŠ¡æ ·æœ¬
    
    Args:
        project_dir: é¡¹ç›®ç›®å½•
        label: æ ·æœ¬æ ‡ç­¾ ('explicit' æˆ– 'non_explicit')
        
    Returns:
        list: æ ·æœ¬åˆ—è¡¨
    """
    samples = []
    source_files = list_source_files(project_dir)
    
    print(f"ğŸ”§ ç”Ÿæˆè¡¥å…¨æ ·æœ¬ [{label}] - {len(source_files)} ä¸ªæ–‡ä»¶")
    
    for f in tqdm(source_files, desc=f"å¤„ç† {label} æ ·æœ¬"):
        try:
            with open(f, "r", encoding="utf-8") as src:
                content = src.read()
            
            # è§£æASTï¼Œæå–å‡½æ•°å®šä¹‰
            try:
                functions = extract_functions_from_code(content, f)
            except Exception as e:
                print(f"âš ï¸ è§£æé”™è¯¯ï¼Œè·³è¿‡æ–‡ä»¶: {f} - {e}")
                continue
            
            # ä¸ºæ¯ä¸ªå‡½æ•°ç”Ÿæˆè¡¥å…¨æ ·æœ¬
            for func_info in functions:
                if len(func_info['body'].strip()) < 10:  # è·³è¿‡å¤ªçŸ­çš„å‡½æ•°
                    continue
                    
                # åˆ›å»ºæ©ç›–ç‰ˆæœ¬
                masked_content = create_masked_function(content, func_info)
                
                sample = {
                    "file": f,
                    "input": masked_content,
                    "target": func_info['body'],
                    "function_name": func_info['name'],
                    "view": label,
                    "line_start": func_info['line_start'],
                    "line_end": func_info['line_end']
                }
                samples.append(sample)
                
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ä»¶å¤±è´¥: {f} - {e}")
            continue
    
    print(f"âœ… ç”Ÿæˆ {len(samples)} ä¸ªè¡¥å…¨æ ·æœ¬ [{label}]")
    return samples


def extract_functions_from_code(content, file_path):
    """ä»ä»£ç ä¸­æå–å‡½æ•°ä¿¡æ¯ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰"""
    file_ext = os.path.splitext(file_path)[1].lower()
    
    if file_ext == '.py':
        return extract_python_functions(content)
    elif file_ext == '.java':
        return extract_java_functions(content)
    elif file_ext in ['.js', '.ts']:
        return extract_javascript_functions(content)
    elif file_ext in ['.cpp', '.c']:
        return extract_cpp_functions(content)
    elif file_ext == '.cs':
        return extract_csharp_functions(content)
    else:
        # å¯¹äºå…¶ä»–è¯­è¨€ï¼Œä½¿ç”¨ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼
        return extract_functions_with_regex(content, file_ext)


def extract_python_functions(content):
    """æå–Pythonå‡½æ•°"""
    functions = []
    try:
        tree = ast.parse(content)
        lines = content.split('\n')
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                start_line = node.lineno - 1
                end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 1
                
                func_lines = lines[start_line:end_line]
                func_body = '\n'.join(func_lines)
                
                body_start = func_body.find(':') + 1
                if body_start > 0:
                    body_content = func_body[body_start:].strip()
                    if body_content:
                        functions.append({
                            'name': node.name,
                            'body': body_content,
                            'line_start': node.lineno,
                            'line_end': node.end_lineno if hasattr(node, 'end_lineno') else node.lineno
                        })
    except Exception:
        pass
    
    return functions


def extract_java_functions(content):
    """æå–Javaæ–¹æ³•"""
    import re
    functions = []
    lines = content.split('\n')
    
    # Javaæ–¹æ³•æ¨¡å¼ï¼šä¿®é¥°ç¬¦ + è¿”å›ç±»å‹ + æ–¹æ³•å + å‚æ•° + {
    method_pattern = r'(\s*(?:public|private|protected|static|final|abstract|synchronized)\s+)*(\w+(?:<[^>]*>)?)\s+(\w+)\s*\([^)]*\)\s*\{'
    
    for i, line in enumerate(lines):
        match = re.search(method_pattern, line)
        if match:
            method_name = match.group(3)
            
            # æ‰¾åˆ°æ–¹æ³•ä½“çš„ç»“æŸä½ç½®
            brace_count = 0
            start_line = i
            end_line = i
            
            for j in range(i, len(lines)):
                line_content = lines[j]
                brace_count += line_content.count('{')
                brace_count -= line_content.count('}')
                
                if brace_count == 0 and j > i:
                    end_line = j
                    break
            
            # æå–æ–¹æ³•ä½“
            method_lines = lines[start_line:end_line + 1]
            method_body = '\n'.join(method_lines)
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª{åçš„å†…å®¹
            body_start = method_body.find('{') + 1
            if body_start > 0:
                body_content = method_body[body_start:].strip()
                if body_content and len(body_content) > 10:
                    functions.append({
                        'name': method_name,
                        'body': body_content,
                        'line_start': start_line + 1,
                        'line_end': end_line + 1
                    })
    
    return functions


def extract_javascript_functions(content):
    """æå–JavaScript/TypeScriptå‡½æ•°"""
    import re
    functions = []
    lines = content.split('\n')
    
    # JavaScriptå‡½æ•°æ¨¡å¼
    patterns = [
        r'function\s+(\w+)\s*\([^)]*\)\s*\{',  # function name() {}
        r'(\w+)\s*:\s*function\s*\([^)]*\)\s*\{',  # name: function() {}
        r'(\w+)\s*\([^)]*\)\s*=>\s*\{',  # name() => {}
        r'const\s+(\w+)\s*=\s*\([^)]*\)\s*=>\s*\{',  # const name = () => {}
    ]
    
    for pattern in patterns:
        for i, line in enumerate(lines):
            match = re.search(pattern, line)
            if match:
                func_name = match.group(1)
                
                # æ‰¾åˆ°å‡½æ•°ä½“çš„ç»“æŸä½ç½®
                brace_count = 0
                start_line = i
                end_line = i
                
                for j in range(i, len(lines)):
                    line_content = lines[j]
                    brace_count += line_content.count('{')
                    brace_count -= line_content.count('}')
                    
                    if brace_count == 0 and j > i:
                        end_line = j
                        break
                
                # æå–å‡½æ•°ä½“
                func_lines = lines[start_line:end_line + 1]
                func_body = '\n'.join(func_lines)
                
                body_start = func_body.find('{') + 1
                if body_start > 0:
                    body_content = func_body[body_start:].strip()
                    if body_content and len(body_content) > 10:
                        functions.append({
                            'name': func_name,
                            'body': body_content,
                            'line_start': start_line + 1,
                            'line_end': end_line + 1
                        })
    
    return functions


def extract_cpp_functions(content):
    """æå–C++å‡½æ•°"""
    import re
    functions = []
    lines = content.split('\n')
    
    # C++å‡½æ•°æ¨¡å¼
    function_pattern = r'(\w+(?:\s*<[^>]*>)?)\s+(\w+)\s*\([^)]*\)\s*\{'
    
    for i, line in enumerate(lines):
        match = re.search(function_pattern, line)
        if match:
            func_name = match.group(2)
            
            # æ‰¾åˆ°å‡½æ•°ä½“çš„ç»“æŸä½ç½®
            brace_count = 0
            start_line = i
            end_line = i
            
            for j in range(i, len(lines)):
                line_content = lines[j]
                brace_count += line_content.count('{')
                brace_count -= line_content.count('}')
                
                if brace_count == 0 and j > i:
                    end_line = j
                    break
            
            # æå–å‡½æ•°ä½“
            func_lines = lines[start_line:end_line + 1]
            func_body = '\n'.join(func_lines)
            
            body_start = func_body.find('{') + 1
            if body_start > 0:
                body_content = func_body[body_start:].strip()
                if body_content and len(body_content) > 10:
                    functions.append({
                        'name': func_name,
                        'body': body_content,
                        'line_start': start_line + 1,
                        'line_end': end_line + 1
                    })
    
    return functions


def extract_csharp_functions(content):
    """æå–C#æ–¹æ³•"""
    import re
    functions = []
    lines = content.split('\n')
    
    # C#æ–¹æ³•æ¨¡å¼
    method_pattern = r'(\s*(?:public|private|protected|internal|static|virtual|override|abstract|sealed)\s+)*(\w+(?:<[^>]*>)?)\s+(\w+)\s*\([^)]*\)\s*\{'
    
    for i, line in enumerate(lines):
        match = re.search(method_pattern, line)
        if match:
            method_name = match.group(3)
            
            # æ‰¾åˆ°æ–¹æ³•ä½“çš„ç»“æŸä½ç½®
            brace_count = 0
            start_line = i
            end_line = i
            
            for j in range(i, len(lines)):
                line_content = lines[j]
                brace_count += line_content.count('{')
                brace_count -= line_content.count('}')
                
                if brace_count == 0 and j > i:
                    end_line = j
                    break
            
            # æå–æ–¹æ³•ä½“
            method_lines = lines[start_line:end_line + 1]
            method_body = '\n'.join(method_lines)
            
            body_start = method_body.find('{') + 1
            if body_start > 0:
                body_content = method_body[body_start:].strip()
                if body_content and len(body_content) > 10:
                    functions.append({
                        'name': method_name,
                        'body': body_content,
                        'line_start': start_line + 1,
                        'line_end': end_line + 1
                    })
    
    return functions


def extract_functions_with_regex(content, file_ext):
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å‡½æ•°ï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
    import re
    functions = []
    lines = content.split('\n')
    
    # é€šç”¨å‡½æ•°æ¨¡å¼
    patterns = [
        r'(\w+)\s*\([^)]*\)\s*\{',  # name() {
        r'function\s+(\w+)\s*\([^)]*\)\s*\{',  # function name() {
    ]
    
    for pattern in patterns:
        for i, line in enumerate(lines):
            match = re.search(pattern, line)
            if match:
                func_name = match.group(1)
                
                # æ‰¾åˆ°å‡½æ•°ä½“çš„ç»“æŸä½ç½®
                brace_count = 0
                start_line = i
                end_line = i
                
                for j in range(i, len(lines)):
                    line_content = lines[j]
                    brace_count += line_content.count('{')
                    brace_count -= line_content.count('}')
                    
                    if brace_count == 0 and j > i:
                        end_line = j
                        break
                
                # æå–å‡½æ•°ä½“
                func_lines = lines[start_line:end_line + 1]
                func_body = '\n'.join(func_lines)
                
                body_start = func_body.find('{') + 1
                if body_start > 0:
                    body_content = func_body[body_start:].strip()
                    if body_content and len(body_content) > 10:
                        functions.append({
                            'name': func_name,
                            'body': body_content,
                            'line_start': start_line + 1,
                            'line_end': end_line + 1
                        })
    
    return functions


def create_masked_function(content, func_info):
    """åˆ›å»ºæ©ç›–å‡½æ•°ä½“çš„ç‰ˆæœ¬"""
    lines = content.split('\n')
    start_line = func_info['line_start'] - 1
    end_line = func_info['line_end'] - 1
    
    # æ‰¾åˆ°å‡½æ•°å®šä¹‰è¡Œ
    func_def_line = start_line
    for i in range(start_line, min(end_line + 1, len(lines))):
        if 'def ' in lines[i] and func_info['name'] in lines[i]:
            func_def_line = i
            break
    
    # åˆ›å»ºæ©ç›–ç‰ˆæœ¬
    masked_lines = lines[:func_def_line + 1]  # ä¿ç•™å‡½æ•°å®šä¹‰è¡Œ
    masked_lines.append("    # [MASKED_FUNCTION_BODY]")
    masked_lines.extend(lines[end_line + 1:])  # ä¿ç•™å‡½æ•°åçš„å†…å®¹
    
    return '\n'.join(masked_lines)


# ========= 3ï¸âƒ£ å‡½æ•°è°ƒç”¨ä¸å¯¼å…¥å›¾åˆ†æ ==========
class FunctionCallAnalyzer(ast.NodeVisitor):
    """ASTè®¿é—®å™¨ï¼Œç”¨äºåˆ†æå‡½æ•°è°ƒç”¨å…³ç³»"""
    
    def __init__(self, filename):
        self.filename = filename
        self.calls = []  # (caller, callee)
        self.current_func = None

    def visit_FunctionDef(self, node):
        prev = self.current_func
        self.current_func = node.name
        self.generic_visit(node)
        self.current_func = prev

    def visit_Call(self, node):
        if isinstance(node.func, ast.Attribute):
            name = f"{ast.unparse(node.func)}"
        elif isinstance(node.func, ast.Name):
            name = node.func.id
        else:
            name = "unknown"
        
        if self.current_func:
            self.calls.append((self.current_func, name))
        self.generic_visit(node)


def parse_imports(filepath):
    """è§£ææ–‡ä»¶çš„å¯¼å…¥è¯­å¥ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰"""
    file_ext = os.path.splitext(filepath)[1].lower()
    
    if file_ext == '.py':
        return parse_python_imports(filepath)
    elif file_ext == '.java':
        return parse_java_imports(filepath)
    elif file_ext in ['.js', '.ts']:
        return parse_javascript_imports(filepath)
    elif file_ext in ['.cpp', '.c']:
        return parse_cpp_imports(filepath)
    elif file_ext == '.cs':
        return parse_csharp_imports(filepath)
    else:
        return parse_imports_with_regex(filepath)


def parse_python_imports(filepath):
    """è§£æPythonå¯¼å…¥è¯­å¥"""
    imports = []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            tree = ast.parse(f.read(), filename=filepath)
    except Exception:
        return imports
    
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.append(alias.name)
        elif isinstance(node, ast.ImportFrom):
            if node.module:
                imports.append(node.module)
    
    return imports


def parse_java_imports(filepath):
    """è§£æJavaå¯¼å…¥è¯­å¥"""
    import re
    imports = []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        
        # Java importè¯­å¥æ¨¡å¼
        import_pattern = r'import\s+(?:static\s+)?([^;]+);'
        matches = re.findall(import_pattern, content)
        
        for match in matches:
            imports.append(match.strip())
    except Exception:
        pass
    
    return imports


def parse_javascript_imports(filepath):
    """è§£æJavaScript/TypeScriptå¯¼å…¥è¯­å¥"""
    import re
    imports = []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        
        # JavaScript/TypeScriptå¯¼å…¥æ¨¡å¼
        patterns = [
            r'import\s+.*?\s+from\s+[\'"]([^\'"]+)[\'"]',  # import ... from '...'
            r'import\s+[\'"]([^\'"]+)[\'"]',  # import '...'
            r'require\s*\(\s*[\'"]([^\'"]+)[\'"]\s*\)',  # require('...')
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content)
            imports.extend(matches)
    except Exception:
        pass
    
    return imports


def parse_cpp_imports(filepath):
    """è§£æC++å¯¼å…¥è¯­å¥"""
    import re
    imports = []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        
        # C++ includeè¯­å¥æ¨¡å¼
        include_pattern = r'#include\s*[<"]([^>"]+)[>"]'
        matches = re.findall(include_pattern, content)
        
        for match in matches:
            imports.append(match.strip())
    except Exception:
        pass
    
    return imports


def parse_csharp_imports(filepath):
    """è§£æC#å¯¼å…¥è¯­å¥"""
    import re
    imports = []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        
        # C# usingè¯­å¥æ¨¡å¼
        using_pattern = r'using\s+([^;]+);'
        matches = re.findall(using_pattern, content)
        
        for match in matches:
            imports.append(match.strip())
    except Exception:
        pass
    
    return imports


def parse_imports_with_regex(filepath):
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æå¯¼å…¥è¯­å¥ï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
    import re
    imports = []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        
        # é€šç”¨å¯¼å…¥æ¨¡å¼
        patterns = [
            r'import\s+([^;]+);',  # import ...;
            r'#include\s*[<"]([^>"]+)[>"]',  # #include <...>
            r'using\s+([^;]+);',  # using ...;
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content)
            imports.extend(matches)
    except Exception:
        pass
    
    return imports


def analyze_calls_with_regex(content, filepath):
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†æå‡½æ•°è°ƒç”¨ï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
    import re
    calls = []
    lines = content.split('\n')
    
    # é¦–å…ˆæå–æ‰€æœ‰å‡½æ•°å®šä¹‰
    functions = extract_functions_from_code(content, filepath)
    function_names = [func['name'] for func in functions]
    
    # åˆ†ææ¯ä¸ªå‡½æ•°ä¸­çš„è°ƒç”¨
    for func in functions:
        func_name = func['name']
        start_line = func['line_start'] - 1
        end_line = func['line_end'] - 1
        
        # æå–å‡½æ•°ä½“å†…å®¹
        func_lines = lines[start_line:end_line]
        func_content = '\n'.join(func_lines)
        
        # æŸ¥æ‰¾å‡½æ•°è°ƒç”¨
        # åŒ¹é…æ¨¡å¼ï¼šå‡½æ•°å(å‚æ•°)
        call_pattern = r'(\w+)\s*\('
        matches = re.findall(call_pattern, func_content)
        
        for match in matches:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„å‡½æ•°
            if match in function_names and match != func_name:
                calls.append((func_name, match))
    
    return calls


def compute_coupling(project_dir):
    """
    è®¡ç®—é¡¹ç›®çš„è€¦åˆåº¦æŒ‡æ ‡
    
    Args:
        project_dir: é¡¹ç›®ç›®å½•
        
    Returns:
        dict: æ¯ä¸ªæ–‡ä»¶çš„è€¦åˆåº¦æŒ‡æ ‡
    """
    files = list_source_files(project_dir)
    import_graph = nx.DiGraph()
    call_graph = nx.DiGraph()
    
    print(f"ğŸ” è®¡ç®—è€¦åˆåº¦æŒ‡æ ‡ - {len(files)} ä¸ªæ–‡ä»¶")
    
    # æ„å»ºå¯¼å…¥å›¾
    for f in tqdm(files, desc="åˆ†æå¯¼å…¥å…³ç³»"):
        imports = parse_imports(f)
        for imp in imports:
            import_graph.add_edge(f, imp)
    
    # æ„å»ºè°ƒç”¨å›¾
    for f in tqdm(files, desc="åˆ†æè°ƒç”¨å…³ç³»"):
        try:
            with open(f, "r", encoding="utf-8") as src:
                content = src.read()
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆ†ææ–¹æ³•
            file_ext = os.path.splitext(f)[1].lower()
            if file_ext == '.py':
                tree = ast.parse(content)
                analyzer = FunctionCallAnalyzer(f)
                analyzer.visit(tree)
                for caller, callee in analyzer.calls:
                    call_graph.add_edge(f"{f}:{caller}", callee)
            else:
                # å¯¹äºå…¶ä»–è¯­è¨€ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†æ
                calls = analyze_calls_with_regex(content, f)
                for caller, callee in calls:
                    call_graph.add_edge(f"{f}:{caller}", callee)
        except Exception:
            continue
    
    # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„è€¦åˆåº¦æŒ‡æ ‡
    results = {}
    for f in files:
        import_deg = import_graph.out_degree(f)
        call_deg = sum(1 for n in call_graph.nodes if n.startswith(f + ":"))
        coupling_score = round(import_deg * 0.4 + call_deg * 0.6, 3)
        
        results[f] = {
            "import_coupling": import_deg,
            "call_coupling": call_deg,
            "coupling_score": coupling_score
        }
    
    return results


# ========= 4ï¸âƒ£ è€¦åˆåº¦ç»Ÿè®¡åˆ†æä¸å¯è§†åŒ– ==========
def analyze_coupling_diff(explicit_coupling, implicit_coupling, out_dir):
    """
    åˆ†ææ˜¾æ€§å’Œéæ˜¾æ€§æ¶æ„çš„è€¦åˆåº¦å·®å¼‚
    
    Args:
        explicit_coupling: æ˜¾æ€§æ¶æ„è€¦åˆåº¦æ•°æ®
        implicit_coupling: éæ˜¾æ€§æ¶æ„è€¦åˆåº¦æ•°æ®
        out_dir: è¾“å‡ºç›®å½•
    """
    # è½¬æ¢ä¸ºDataFrame
    df_exp = pd.DataFrame([
        {"file": f, **v, "view": "explicit"} for f, v in explicit_coupling.items()
    ])
    df_imp = pd.DataFrame([
        {"file": f, **v, "view": "non_explicit"} for f, v in implicit_coupling.items()
    ])
    df = pd.concat([df_exp, df_imp], ignore_index=True)
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_csv = Path(out_dir) / "coupling_report.csv"
    ensure_dir(out_dir)
    df.to_csv(report_csv, index=False, encoding="utf-8-sig")
    print(f"ğŸ“Š è€¦åˆåº¦æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_csv}")
    
    # è®¡ç®—å¹³å‡å€¼
    metrics = ["import_coupling", "call_coupling", "coupling_score"]
    summary = df.groupby("view")[metrics].mean()
    print("\n=== å¹³å‡è€¦åˆåº¦å¯¹æ¯” ===")
    print(summary)
    
    # ç»Ÿè®¡æ£€éªŒ
    print("\n=== ç»Ÿè®¡æ£€éªŒç»“æœ ===")
    signif_dict = {}
    for m in metrics:
        exp_values = df_exp[m].values
        imp_values = df_imp[m].values
        t_stat, p_val = ttest_ind(exp_values, imp_values, equal_var=False)
        signif_dict[m] = p_val
        delta = summary.loc['non_explicit', m] - summary.loc['explicit', m]
        print(f"{m}: Î” = {delta:.3f}, p-value = {p_val:.4f}")
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾
    plt.figure(figsize=(12, 8))
    x = np.arange(len(metrics))
    bar_width = 0.35
    
    plt.bar(x - bar_width/2, summary.loc["explicit"], bar_width, 
            label="æ˜¾æ€§æ¶æ„", color='skyblue', alpha=0.8)
    plt.bar(x + bar_width/2, summary.loc["non_explicit"], bar_width, 
            label="éæ˜¾æ€§æ¶æ„", color='lightcoral', alpha=0.8)
    
    # æ ‡æ³¨ç»Ÿè®¡æ˜¾è‘—æ€§
    for idx, m in enumerate(metrics):
        delta = summary.loc["non_explicit", m] - summary.loc["explicit", m]
        p_val = signif_dict[m]
        if p_val < 0.001:
            star = "***"
        elif p_val < 0.01:
            star = "**"
        elif p_val < 0.05:
            star = "*"
        else:
            star = "ns"
        
        y_pos = max(summary.loc["explicit", m], summary.loc["non_explicit", m]) + 0.5
        plt.text(idx, y_pos, f"Î”={delta:.2f}\n{star}", 
                ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.xticks(x, metrics)
    plt.ylabel("å¹³å‡è€¦åˆåº¦")
    plt.title("æ˜¾æ€§æ¶æ„ vs éæ˜¾æ€§æ¶æ„ - è€¦åˆåº¦å¯¹æ¯”")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    chart_path = Path(out_dir) / "coupling_comparison.png"
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“ˆ å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜è‡³: {chart_path}")
    plt.show()


# ========= 5ï¸âƒ£ æ ·æœ¬å¤„ç†ä¸åˆ’åˆ† ==========
def attach_coupling(samples, coupling_dict):
    """ä¸ºæ ·æœ¬é™„åŠ è€¦åˆåº¦ä¿¡æ¯"""
    for s in samples:
        f = s["file"]
        if f in coupling_dict:
            s["coupling"] = coupling_dict[f]
        else:
            s["coupling"] = {"import_coupling": 0, "call_coupling": 0, "coupling_score": 0}
    return samples


def save_and_split(samples, out_prefix):
    """ä¿å­˜æ ·æœ¬å¹¶åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†"""
    ensure_dir(os.path.dirname(out_prefix))
    
    # ä¿å­˜å®Œæ•´æ ·æœ¬
    with open(out_prefix + ".json", "w", encoding="utf-8") as f:
        json.dump(samples, f, indent=2, ensure_ascii=False)
    
    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    train, val = train_test_split(samples, test_size=0.2, random_state=42)
    
    with open(out_prefix + "_train.json", "w", encoding="utf-8") as f:
        json.dump(train, f, indent=2, ensure_ascii=False)
    with open(out_prefix + "_val.json", "w", encoding="utf-8") as f:
        json.dump(val, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ ·æœ¬åˆ’åˆ†å®Œæˆ: è®­ç»ƒé›† {len(train)} / éªŒè¯é›† {len(val)}")


# ========= ä¸»æµç¨‹ ==========
def main(src_dir, out_dir):
    """
    ä¸»æ•°æ®æ„å»ºæµç¨‹
    
    Args:
        src_dir: æºä»£ç ç›®å½•
        out_dir: è¾“å‡ºç›®å½•
    """
    print("ğŸš€ å¼€å§‹æ˜¾æ€§æ¶æ„å®éªŒæ•°æ®æ„å»º")
    print(f"ğŸ“‚ æºä»£ç ç›®å½•: {src_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {out_dir}")
    
    # 1. ç”Ÿæˆæ˜¾æ€§/éæ˜¾æ€§æ¶æ„å‰¯æœ¬
    explicit_dir, implicit_dir = make_copies(src_dir, out_dir)
    
    # 2. ç”Ÿæˆè¡¥å…¨ä»»åŠ¡æ ·æœ¬
    exp_samples = make_completion_samples(explicit_dir, "explicit")
    imp_samples = make_completion_samples(implicit_dir, "non_explicit")
    
    # 3. è®¡ç®—è€¦åˆåº¦æŒ‡æ ‡
    exp_coupling = compute_coupling(explicit_dir)
    imp_coupling = compute_coupling(implicit_dir)
    
    # 4. åˆ†æè€¦åˆåº¦å·®å¼‚
    analyze_coupling_diff(exp_coupling, imp_coupling, out_dir)
    
    # 5. é™„åŠ è€¦åˆåº¦ä¿¡æ¯å¹¶ä¿å­˜
    exp_samples = attach_coupling(exp_samples, exp_coupling)
    imp_samples = attach_coupling(imp_samples, imp_coupling)
    
    save_and_split(exp_samples, f"{out_dir}/explicit_samples")
    save_and_split(imp_samples, f"{out_dir}/non_explicit_samples")
    
    print("ğŸ¯ æ•°æ®æ„å»ºæµç¨‹å®Œæˆï¼")
    print(f"ğŸ“Š æ˜¾æ€§æ¶æ„æ ·æœ¬: {len(exp_samples)} ä¸ª")
    print(f"ğŸ“Š éæ˜¾æ€§æ¶æ„æ ·æœ¬: {len(imp_samples)} ä¸ª")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="æ˜¾æ€§æ¶æ„å®éªŒæ•°æ®æ„å»ºè„šæœ¬")
    parser.add_argument("--src", required=True, help="æºä»£ç é¡¹ç›®ç›®å½•")
    parser.add_argument("--out", default="./dataset_out", help="è¾“å‡ºç›®å½•")
    args = parser.parse_args()
    
    main(args.src, args.out)
