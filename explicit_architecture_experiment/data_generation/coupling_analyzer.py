#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
coupling_analyzer.py
----------------------------------------------------
å‡½æ•°è€¦åˆåº¦åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
1. åŸºäºASTåˆ†æå‡½æ•°è°ƒç”¨å…³ç³»
2. è®¡ç®—å¤šç§è€¦åˆåº¦æŒ‡æ ‡
3. ç”Ÿæˆè€¦åˆåº¦æŠ¥å‘Šå’Œå¯è§†åŒ–
4. æ”¯æŒä¸åŒç¼–ç¨‹è¯­è¨€çš„è€¦åˆåº¦åˆ†æ

ä¾èµ–ï¼š
    pip install astor networkx matplotlib seaborn
----------------------------------------------------
"""

import os
import ast
import json
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any
from collections import defaultdict


class CouplingAnalyzer:
    """å‡½æ•°è€¦åˆåº¦åˆ†æå™¨"""
    
    def __init__(self, language="python"):
        self.language = language
        self.call_graph = nx.DiGraph()
        self.import_graph = nx.DiGraph()
        self.function_index = {}  # {function_name: file_path}
        self.file_functions = defaultdict(list)  # {file_path: [function_names]}
        
    def analyze_project(self, project_dir: str) -> Dict[str, Any]:
        """
        åˆ†ææ•´ä¸ªé¡¹ç›®çš„è€¦åˆåº¦
        
        Args:
            project_dir: é¡¹ç›®ç›®å½•è·¯å¾„
            
        Returns:
            dict: è€¦åˆåº¦åˆ†æç»“æœ
        """
        print(f"ğŸ” å¼€å§‹åˆ†æé¡¹ç›®è€¦åˆåº¦: {project_dir}")
        
        # æ¸…ç©ºä¹‹å‰çš„åˆ†æç»“æœ
        self.call_graph.clear()
        self.import_graph.clear()
        self.function_index.clear()
        self.file_functions.clear()
        
        # è·å–æ‰€æœ‰æºæ–‡ä»¶
        source_files = self._get_source_files(project_dir)
        print(f"ğŸ“„ å‘ç° {len(source_files)} ä¸ªæºæ–‡ä»¶")
        
        # ç¬¬ä¸€éï¼šå»ºç«‹å‡½æ•°ç´¢å¼•
        for file_path in source_files:
            self._index_functions(file_path)
        
        # ç¬¬äºŒéï¼šåˆ†æè°ƒç”¨å…³ç³»
        for file_path in source_files:
            self._analyze_file_coupling(file_path)
        
        # è®¡ç®—è€¦åˆåº¦æŒ‡æ ‡
        coupling_metrics = self._compute_coupling_metrics()
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = self._generate_report(coupling_metrics)
        
        print(f"âœ… è€¦åˆåº¦åˆ†æå®Œæˆ")
        return report
    
    def _get_source_files(self, project_dir: str) -> List[str]:
        """è·å–é¡¹ç›®ä¸­çš„æ‰€æœ‰æºæ–‡ä»¶"""
        source_files = []
        supported_extensions = ['.py', '.java', '.js', '.ts', '.cpp', '.c', '.cs', '.go', '.rs']
        for root, _, files in os.walk(project_dir):
            for file in files:
                if any(file.endswith(ext) for ext in supported_extensions):
                    source_files.append(os.path.join(root, file))
        return source_files
    
    def _index_functions(self, file_path: str):
        """å»ºç«‹å‡½æ•°ç´¢å¼•"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if file_path.endswith('.py'):
                self._index_python_functions(file_path, content)
            # å¯ä»¥æ‰©å±•æ”¯æŒå…¶ä»–è¯­è¨€
                
        except Exception as e:
            print(f"âš ï¸ ç´¢å¼•å‡½æ•°å¤±è´¥: {file_path} - {e}")
    
    def _index_python_functions(self, file_path: str, content: str):
        """ç´¢å¼•Pythonå‡½æ•°"""
        try:
            tree = ast.parse(content, filename=file_path)
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_name = node.name
                    full_name = f"{file_path}:{func_name}"
                    self.function_index[func_name] = file_path
                    self.file_functions[file_path].append(func_name)
                    self.call_graph.add_node(full_name)
        except SyntaxError:
            print(f"âš ï¸ è¯­æ³•é”™è¯¯ï¼Œè·³è¿‡æ–‡ä»¶: {file_path}")
    
    def _analyze_file_coupling(self, file_path: str):
        """åˆ†ææ–‡ä»¶çš„è€¦åˆåº¦"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if file_path.endswith('.py'):
                self._analyze_python_coupling(file_path, content)
                
        except Exception as e:
            print(f"âš ï¸ åˆ†æè€¦åˆåº¦å¤±è´¥: {file_path} - {e}")
    
    def _analyze_python_coupling(self, file_path: str, content: str):
        """åˆ†æPythonæ–‡ä»¶çš„è€¦åˆåº¦"""
        try:
            tree = ast.parse(content, filename=file_path)
            
            # åˆ†æå¯¼å…¥å…³ç³»
            self._analyze_imports(file_path, tree)
            
            # åˆ†æå‡½æ•°è°ƒç”¨å…³ç³»
            self._analyze_function_calls(file_path, tree)
                
        except SyntaxError:
            print(f"âš ï¸ è¯­æ³•é”™è¯¯ï¼Œè·³è¿‡æ–‡ä»¶: {file_path}")
    
    def _analyze_imports(self, file_path: str, tree: ast.AST):
        """åˆ†æå¯¼å…¥å…³ç³»"""
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    self.import_graph.add_edge(file_path, alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    self.import_graph.add_edge(file_path, node.module)
    
    def _analyze_function_calls(self, file_path: str, tree: ast.AST):
        """åˆ†æå‡½æ•°è°ƒç”¨å…³ç³»"""
        class CallVisitor(ast.NodeVisitor):
            def __init__(self, analyzer, file_path):
                self.analyzer = analyzer
                self.file_path = file_path
                self.current_function = None
            
            def visit_FunctionDef(self, node):
                prev_func = self.current_function
                self.current_function = node.name
                self.generic_visit(node)
                self.current_function = prev_func
            
            def visit_Call(self, node):
                if self.current_function:
                    # è·å–è¢«è°ƒç”¨å‡½æ•°å
                    if isinstance(node.func, ast.Name):
                        callee = node.func.id
                    elif isinstance(node.func, ast.Attribute):
                        callee = ast.unparse(node.func)
                    else:
                        callee = "unknown"
                    
                    # å»ºç«‹è°ƒç”¨å…³ç³»
                    caller = f"{self.file_path}:{self.current_function}"
                    if callee in self.analyzer.function_index:
                        callee_file = self.analyzer.function_index[callee]
                        callee_full = f"{callee_file}:{callee}"
                        self.analyzer.call_graph.add_edge(caller, callee_full)
                
                self.generic_visit(node)
        
        visitor = CallVisitor(self, file_path)
        visitor.visit(tree)
    
    def _compute_coupling_metrics(self) -> Dict[str, Any]:
        """è®¡ç®—è€¦åˆåº¦æŒ‡æ ‡"""
        metrics = {}
        
        for file_path in self.file_functions:
            # æ–‡ä»¶çº§æŒ‡æ ‡
            import_in = self.import_graph.in_degree(file_path)
            import_out = self.import_graph.out_degree(file_path)
            
            # å‡½æ•°çº§æŒ‡æ ‡
            file_functions = self.file_functions[file_path]
            fan_in_total = 0
            fan_out_total = 0
            
            for func_name in file_functions:
                func_node = f"{file_path}:{func_name}"
                fan_in = self.call_graph.in_degree(func_node)
                fan_out = self.call_graph.out_degree(func_node)
                fan_in_total += fan_in
                fan_out_total += fan_out
            
            # è®¡ç®—ç»¼åˆè€¦åˆåº¦
            coupling_score = import_in * 0.2 + import_out * 0.2 + fan_in_total * 0.3 + fan_out_total * 0.3
            
            metrics[file_path] = {
                "import_in": import_in,
                "import_out": import_out,
                "fan_in_total": fan_in_total,
                "fan_out_total": fan_out_total,
                "coupling_score": round(coupling_score, 3),
                "function_count": len(file_functions)
            }
        
        return metrics
    
    def _generate_report(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        coupling_scores = [m["coupling_score"] for m in metrics.values()]
        import_in_scores = [m["import_in"] for m in metrics.values()]
        import_out_scores = [m["import_out"] for m in metrics.values()]
        fan_in_scores = [m["fan_in_total"] for m in metrics.values()]
        fan_out_scores = [m["fan_out_total"] for m in metrics.values()]
        
        report = {
            "summary": {
                "total_files": len(metrics),
                "total_functions": sum(m["function_count"] for m in metrics.values()),
                "avg_coupling_score": np.mean(coupling_scores),
                "max_coupling_score": np.max(coupling_scores),
                "min_coupling_score": np.min(coupling_scores),
                "std_coupling_score": np.std(coupling_scores)
            },
            "metrics": metrics,
            "statistics": {
                "coupling_score": {
                    "mean": np.mean(coupling_scores),
                    "std": np.std(coupling_scores),
                    "median": np.median(coupling_scores),
                    "q25": np.percentile(coupling_scores, 25),
                    "q75": np.percentile(coupling_scores, 75)
                },
                "import_in": {
                    "mean": np.mean(import_in_scores),
                    "std": np.std(import_in_scores)
                },
                "import_out": {
                    "mean": np.mean(import_out_scores),
                    "std": np.std(import_out_scores)
                },
                "fan_in": {
                    "mean": np.mean(fan_in_scores),
                    "std": np.std(fan_in_scores)
                },
                "fan_out": {
                    "mean": np.mean(fan_out_scores),
                    "std": np.std(fan_out_scores)
                }
            }
        }
        
        return report
    
    def save_report(self, report: Dict[str, Any], output_path: str):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        ensure_dir(os.path.dirname(output_path))
        
        # ä¿å­˜JSONæŠ¥å‘Š
        json_path = output_path.replace('.csv', '.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜CSVæŠ¥å‘Š
        df_data = []
        for file_path, metrics in report["metrics"].items():
            row = {"file": file_path}
            row.update(metrics)
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        print(f"ğŸ“Š è€¦åˆåº¦æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   JSON: {json_path}")
        print(f"   CSV: {output_path}")
    
    def visualize_coupling(self, report: Dict[str, Any], output_dir: str):
        """å¯è§†åŒ–è€¦åˆåº¦åˆ†æç»“æœ"""
        ensure_dir(output_dir)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. è€¦åˆåº¦åˆ†å¸ƒç›´æ–¹å›¾
        coupling_scores = [m["coupling_score"] for m in report["metrics"].values()]
        
        plt.figure(figsize=(12, 8))
        
        # å­å›¾1: è€¦åˆåº¦åˆ†å¸ƒ
        plt.subplot(2, 2, 1)
        plt.hist(coupling_scores, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        plt.xlabel('è€¦åˆåº¦åˆ†æ•°')
        plt.ylabel('æ–‡ä»¶æ•°é‡')
        plt.title('è€¦åˆåº¦åˆ†å¸ƒç›´æ–¹å›¾')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2: å¯¼å…¥å…³ç³»æ•£ç‚¹å›¾
        plt.subplot(2, 2, 2)
        import_in = [m["import_in"] for m in report["metrics"].values()]
        import_out = [m["import_out"] for m in report["metrics"].values()]
        plt.scatter(import_in, import_out, alpha=0.6, color='lightcoral')
        plt.xlabel('å¯¼å…¥å…¥åº¦')
        plt.ylabel('å¯¼å…¥å‡ºåº¦')
        plt.title('å¯¼å…¥å…³ç³»æ•£ç‚¹å›¾')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾3: å‡½æ•°è°ƒç”¨å…³ç³»æ•£ç‚¹å›¾
        plt.subplot(2, 2, 3)
        fan_in = [m["fan_in_total"] for m in report["metrics"].values()]
        fan_out = [m["fan_out_total"] for m in report["metrics"].values()]
        plt.scatter(fan_in, fan_out, alpha=0.6, color='lightgreen')
        plt.xlabel('å‡½æ•°è°ƒç”¨å…¥åº¦')
        plt.ylabel('å‡½æ•°è°ƒç”¨å‡ºåº¦')
        plt.title('å‡½æ•°è°ƒç”¨å…³ç³»æ•£ç‚¹å›¾')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾4: è€¦åˆåº¦ç®±çº¿å›¾
        plt.subplot(2, 2, 4)
        plt.boxplot(coupling_scores, patch_artist=True, 
                   boxprops=dict(facecolor='lightblue', alpha=0.7))
        plt.ylabel('è€¦åˆåº¦åˆ†æ•°')
        plt.title('è€¦åˆåº¦ç®±çº¿å›¾')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        chart_path = os.path.join(output_dir, "coupling_analysis.png")
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ˆ è€¦åˆåº¦åˆ†æå›¾è¡¨å·²ä¿å­˜: {chart_path}")
        plt.show()
    
    def compare_architectures(self, explicit_report: Dict[str, Any], 
                            implicit_report: Dict[str, Any], 
                            output_dir: str):
        """æ¯”è¾ƒæ˜¾æ€§å’Œéæ˜¾æ€§æ¶æ„çš„è€¦åˆåº¦å·®å¼‚"""
        ensure_dir(output_dir)
        
        # æå–è€¦åˆåº¦æ•°æ®
        exp_scores = [m["coupling_score"] for m in explicit_report["metrics"].values()]
        imp_scores = [m["coupling_score"] for m in implicit_report["metrics"].values()]
        
        # ç»Ÿè®¡æ£€éªŒ
        from scipy.stats import ttest_ind, mannwhitneyu
        
        t_stat, t_p = ttest_ind(exp_scores, imp_scores)
        u_stat, u_p = mannwhitneyu(exp_scores, imp_scores, alternative='two-sided')
        
        # è®¡ç®—æ•ˆåº”é‡
        from scipy.stats import cohen_d
        effect_size = cohen_d(exp_scores, imp_scores)
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        plt.figure(figsize=(15, 10))
        
        # å­å›¾1: ç®±çº¿å›¾å¯¹æ¯”
        plt.subplot(2, 3, 1)
        data_to_plot = [exp_scores, imp_scores]
        labels = ['æ˜¾æ€§æ¶æ„', 'éæ˜¾æ€§æ¶æ„']
        plt.boxplot(data_to_plot, labels=labels, patch_artist=True,
                   boxprops=dict(facecolor='lightblue', alpha=0.7),
                   medianprops=dict(color='red', linewidth=2))
        plt.ylabel('è€¦åˆåº¦åˆ†æ•°')
        plt.title('æ¶æ„è€¦åˆåº¦å¯¹æ¯”')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2: ç›´æ–¹å›¾å¯¹æ¯”
        plt.subplot(2, 3, 2)
        plt.hist(exp_scores, bins=15, alpha=0.7, label='æ˜¾æ€§æ¶æ„', color='skyblue')
        plt.hist(imp_scores, bins=15, alpha=0.7, label='éæ˜¾æ€§æ¶æ„', color='lightcoral')
        plt.xlabel('è€¦åˆåº¦åˆ†æ•°')
        plt.ylabel('æ–‡ä»¶æ•°é‡')
        plt.title('è€¦åˆåº¦åˆ†å¸ƒå¯¹æ¯”')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­å›¾3: å¹³å‡å€¼å¯¹æ¯”
        plt.subplot(2, 3, 3)
        means = [np.mean(exp_scores), np.mean(imp_scores)]
        stds = [np.std(exp_scores), np.std(imp_scores)]
        x_pos = [0, 1]
        plt.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7, 
               color=['skyblue', 'lightcoral'])
        plt.xticks(x_pos, labels)
        plt.ylabel('å¹³å‡è€¦åˆåº¦')
        plt.title('å¹³å‡è€¦åˆåº¦å¯¹æ¯”')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾4: ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
        plt.subplot(2, 3, 4)
        exp_sorted = np.sort(exp_scores)
        imp_sorted = np.sort(imp_scores)
        exp_cdf = np.arange(1, len(exp_sorted) + 1) / len(exp_sorted)
        imp_cdf = np.arange(1, len(imp_sorted) + 1) / len(imp_sorted)
        plt.plot(exp_sorted, exp_cdf, label='æ˜¾æ€§æ¶æ„', linewidth=2)
        plt.plot(imp_sorted, imp_cdf, label='éæ˜¾æ€§æ¶æ„', linewidth=2)
        plt.xlabel('è€¦åˆåº¦åˆ†æ•°')
        plt.ylabel('ç´¯ç§¯æ¦‚ç‡')
        plt.title('ç´¯ç§¯åˆ†å¸ƒå‡½æ•°')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­å›¾5: æ•£ç‚¹å›¾
        plt.subplot(2, 3, 5)
        plt.scatter(range(len(exp_scores)), exp_scores, alpha=0.6, 
                   label='æ˜¾æ€§æ¶æ„', color='skyblue')
        plt.scatter(range(len(imp_scores)), imp_scores, alpha=0.6, 
                   label='éæ˜¾æ€§æ¶æ„', color='lightcoral')
        plt.xlabel('æ–‡ä»¶ç´¢å¼•')
        plt.ylabel('è€¦åˆåº¦åˆ†æ•°')
        plt.title('è€¦åˆåº¦æ•£ç‚¹å›¾')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­å›¾6: ç»Ÿè®¡ä¿¡æ¯
        plt.subplot(2, 3, 6)
        plt.axis('off')
        stats_text = f"""
        ç»Ÿè®¡æ£€éªŒç»“æœ:
        
        tæ£€éªŒ:
        tç»Ÿè®¡é‡: {t_stat:.4f}
        på€¼: {t_p:.4f}
        
        Mann-Whitney Uæ£€éªŒ:
        Uç»Ÿè®¡é‡: {u_stat:.4f}
        på€¼: {u_p:.4f}
        
        æ•ˆåº”é‡ (Cohen's d):
        {effect_size:.4f}
        
        æ ·æœ¬é‡:
        æ˜¾æ€§æ¶æ„: {len(exp_scores)}
        éæ˜¾æ€§æ¶æ„: {len(imp_scores)}
        """
        plt.text(0.1, 0.5, stats_text, fontsize=10, verticalalignment='center',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.5))
        
        plt.tight_layout()
        
        # ä¿å­˜å¯¹æ¯”å›¾
        comparison_path = os.path.join(output_dir, "architecture_comparison.png")
        plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š æ¶æ„å¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_path}")
        plt.show()
        
        # æ‰“å°ç»Ÿè®¡ç»“æœ
        print(f"\nğŸ“Š ç»Ÿè®¡æ£€éªŒç»“æœ:")
        print(f"   tæ£€éªŒ: t={t_stat:.4f}, p={t_p:.4f}")
        print(f"   Mann-Whitney Uæ£€éªŒ: U={u_stat:.4f}, p={u_p:.4f}")
        print(f"   æ•ˆåº”é‡ (Cohen's d): {effect_size:.4f}")
        print(f"   æ˜¾æ€§æ¶æ„å¹³å‡è€¦åˆåº¦: {np.mean(exp_scores):.3f} Â± {np.std(exp_scores):.3f}")
        print(f"   éæ˜¾æ€§æ¶æ„å¹³å‡è€¦åˆåº¦: {np.mean(imp_scores):.3f} Â± {np.std(imp_scores):.3f}")


def ensure_dir(path):
    """ç¡®ä¿ç›®å½•å­˜åœ¨"""
    os.makedirs(path, exist_ok=True)


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å‡½æ•°è€¦åˆåº¦åˆ†æå·¥å…·")
    parser.add_argument("--explicit_dir", required=True, help="æ˜¾æ€§æ¶æ„é¡¹ç›®ç›®å½•")
    parser.add_argument("--implicit_dir", required=True, help="éæ˜¾æ€§æ¶æ„é¡¹ç›®ç›®å½•")
    parser.add_argument("--output_dir", default="./coupling_analysis", help="è¾“å‡ºç›®å½•")
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = CouplingAnalyzer()
    
    # åˆ†ææ˜¾æ€§æ¶æ„
    print("ğŸ” åˆ†ææ˜¾æ€§æ¶æ„è€¦åˆåº¦...")
    explicit_report = analyzer.analyze_project(args.explicit_dir)
    analyzer.save_report(explicit_report, os.path.join(args.output_dir, "explicit_coupling.csv"))
    analyzer.visualize_coupling(explicit_report, args.output_dir)
    
    # åˆ†æéæ˜¾æ€§æ¶æ„
    print("ğŸ” åˆ†æéæ˜¾æ€§æ¶æ„è€¦åˆåº¦...")
    implicit_report = analyzer.analyze_project(args.implicit_dir)
    analyzer.save_report(implicit_report, os.path.join(args.output_dir, "implicit_coupling.csv"))
    
    # æ¯”è¾ƒä¸¤ç§æ¶æ„
    print("ğŸ“Š æ¯”è¾ƒä¸¤ç§æ¶æ„çš„è€¦åˆåº¦å·®å¼‚...")
    analyzer.compare_architectures(explicit_report, implicit_report, args.output_dir)
    
    print("âœ… è€¦åˆåº¦åˆ†æå®Œæˆ!")


if __name__ == "__main__":
    main()
