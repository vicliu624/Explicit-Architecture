@echo off
REM æ¨¡å‹è®­ç»ƒè„šæœ¬ (Windowsç‰ˆæœ¬)

setlocal enabledelayedexpansion

echo ğŸš€ å¼€å§‹æ˜¾æ€§æ¶æ„å®éªŒæ¨¡å‹è®­ç»ƒ...

REM æ£€æŸ¥å‚æ•°
if "%~3"=="" (
    echo ç”¨æ³•: %0 ^<explicit_data^> ^<implicit_data^> [model_name] [output_dir]
    echo ç¤ºä¾‹: %0 .\dataset_out\explicit_samples.json .\dataset_out\non_explicit_samples.json gpt2 .\outputs
    exit /b 1
)

set EXPLICIT_DATA=%~1
set IMPLICIT_DATA=%~2
set MODEL_NAME=%~3
if "%MODEL_NAME%"=="" set MODEL_NAME=gpt2
set OUTPUT_DIR=%~4
if "%OUTPUT_DIR%"=="" set OUTPUT_DIR=.\outputs

echo ğŸ“Š æ˜¾æ€§æ¶æ„æ•°æ®: %EXPLICIT_DATA%
echo ğŸ“Š éæ˜¾æ€§æ¶æ„æ•°æ®: %IMPLICIT_DATA%
echo ğŸ¤– æ¨¡å‹åç§°: %MODEL_NAME%
echo ğŸ“ è¾“å‡ºç›®å½•: %OUTPUT_DIR%

REM æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not exist "%EXPLICIT_DATA%" (
    echo âŒ é”™è¯¯: æ˜¾æ€§æ¶æ„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: %EXPLICIT_DATA%
    exit /b 1
)

if not exist "%IMPLICIT_DATA%" (
    echo âŒ é”™è¯¯: éæ˜¾æ€§æ¶æ„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: %IMPLICIT_DATA%
    exit /b 1
)

REM åˆ›å»ºè¾“å‡ºç›®å½•
if not exist "%OUTPUT_DIR%" mkdir "%OUTPUT_DIR%"

REM è®­ç»ƒæ˜¾æ€§æ¶æ„æ¨¡å‹
echo ğŸ”§ è®­ç»ƒæ˜¾æ€§æ¶æ„æ¨¡å‹...
python ..\..\training\finetune.py --model_name "%MODEL_NAME%" --output_dir "%OUTPUT_DIR%\explicit_model" --train_file "%EXPLICIT_DATA%" --val_file "%EXPLICIT_DATA%" --epochs 3 --batch_size 4 --learning_rate 5e-5

if %ERRORLEVEL% neq 0 (
    echo âŒ æ˜¾æ€§æ¶æ„æ¨¡å‹è®­ç»ƒå¤±è´¥
    exit /b 1
)

REM è®­ç»ƒéæ˜¾æ€§æ¶æ„æ¨¡å‹
echo ğŸ”§ è®­ç»ƒéæ˜¾æ€§æ¶æ„æ¨¡å‹...
python ..\..\training\finetune.py --model_name "%MODEL_NAME%" --output_dir "%OUTPUT_DIR%\implicit_model" --train_file "%IMPLICIT_DATA%" --val_file "%IMPLICIT_DATA%" --epochs 3 --batch_size 4 --learning_rate 5e-5

if %ERRORLEVEL% neq 0 (
    echo âŒ éæ˜¾æ€§æ¶æ„æ¨¡å‹è®­ç»ƒå¤±è´¥
    exit /b 1
)

echo âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!
echo ğŸ“Š è¾“å‡ºæ¨¡å‹:
echo    - æ˜¾æ€§æ¶æ„æ¨¡å‹: %OUTPUT_DIR%\explicit_model
echo    - éæ˜¾æ€§æ¶æ„æ¨¡å‹: %OUTPUT_DIR%\implicit_model

endlocal
